{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1W9ioOP3yi8F57RRgk6VMkHO3wwErqDSi",
      "authorship_tag": "ABX9TyP0cQPqiW/YT8/nHICn9LMC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlugubellySaisri/diabetes/blob/main/Week5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGr48EL9nzOj",
        "outputId": "d95e4dfb-682c-49f7-ca5e-6bd948700b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# every package has to install each time googlecolab runs jyputernoot book.\n",
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = spark.read.csv('drive/My Drive/Colab Notebooks/bezdekIris.data',inferSchema=True, header =True)\\\n",
        ".toDF(\"sep_len\", \"sep_wid\", \"pet_len\", \"pet_wid\", \"label\")\n",
        "\n",
        "dataset.select('label').distinct().show(10)\n",
        "dataset.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg8jvQhqn0ha",
        "outputId": "24873e0a-471d-4e00-f1dc-3ef896a0ec94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|          label|\n",
            "+---------------+\n",
            "| Iris-virginica|\n",
            "|    Iris-setosa|\n",
            "|Iris-versicolor|\n",
            "+---------------+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "vector_assembler = VectorAssembler(\\\n",
        "inputCols=[\"sep_len\", \"sep_wid\", \"pet_len\", \"pet_wid\"],\\\n",
        "outputCol=\"features\")\n",
        "df_temp = vector_assembler.transform(dataset)\n",
        "df_temp.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEUy1A6GoXE6",
        "outputId": "ea7bff53-92a8-4c29-fae4-ce51beba653d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-------+-------+-----------+-----------------+\n",
            "|sep_len|sep_wid|pet_len|pet_wid|      label|         features|\n",
            "+-------+-------+-------+-------+-----------+-----------------+\n",
            "|    4.9|    3.0|    1.4|    0.2|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
            "|    4.7|    3.2|    1.3|    0.2|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
            "|    4.6|    3.1|    1.5|    0.2|Iris-setosa|[4.6,3.1,1.5,0.2]|\n",
            "+-------+-------+-------+-------+-----------+-----------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "l_indexer = StringIndexer(inputCol=\"label\", outputCol=\"labelIndex\")\n",
        "df = l_indexer.fit(df_temp).transform(df_temp)\n",
        "df.select('label','labelIndex').distinct().show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNjIYbBEoieB",
        "outputId": "f628ee6b-123b-42b7-cc7c-18dc4263c010"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----------+\n",
            "|          label|labelIndex|\n",
            "+---------------+----------+\n",
            "|Iris-versicolor|       0.0|\n",
            "| Iris-virginica|       1.0|\n",
            "|    Iris-setosa|       2.0|\n",
            "+---------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(trainingData, testData) = df.randomSplit([0.7, 0.3])\n"
      ],
      "metadata": {
        "id": "BhYx5IrVo8ER"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "dt = DecisionTreeClassifier(labelCol=\"labelIndex\", featuresCol=\"features\",impurity='entropy', maxDepth=4,seed=1234)\n",
        "model = dt.fit(trainingData)\n",
        "predictions = model.transform(testData)"
      ],
      "metadata": {
        "id": "MlcrqQFepBnh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = MulticlassClassificationEvaluator(\\\n",
        "labelCol=\"labelIndex\", predictionCol=\"prediction\",\\\n",
        "metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Test accuracy =  \" , accuracy)\n",
        "print(model.toDebugString)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2yTwOkupDnA",
        "outputId": "e22a1239-1ece-4ef5-8544-3f8f370d661e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy =   0.9423076923076923\n",
            "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_6f2895e3d470, depth=4, numNodes=13, numClasses=3, numFeatures=4\n",
            "  If (feature 2 <= 2.45)\n",
            "   Predict: 2.0\n",
            "  Else (feature 2 > 2.45)\n",
            "   If (feature 3 <= 1.65)\n",
            "    If (feature 2 <= 4.95)\n",
            "     Predict: 0.0\n",
            "    Else (feature 2 > 4.95)\n",
            "     If (feature 1 <= 2.25)\n",
            "      Predict: 1.0\n",
            "     Else (feature 1 > 2.25)\n",
            "      Predict: 0.0\n",
            "   Else (feature 3 > 1.65)\n",
            "    If (feature 2 <= 5.05)\n",
            "     If (feature 1 <= 2.8499999999999996)\n",
            "      Predict: 1.0\n",
            "     Else (feature 1 > 2.8499999999999996)\n",
            "      Predict: 0.0\n",
            "    Else (feature 2 > 5.05)\n",
            "     Predict: 1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is code for multiple classification using logistic Regression\n",
        "from pyspark.ml.classification import OneVsRest\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "train, test = df.randomSplit([0.7, 0.3], seed = 2018)\n",
        "lr = LogisticRegression(maxIter=100, \\\n",
        "\n",
        "                        featuresCol=\"features\", \\\n",
        "\n",
        "                        labelCol='labelIndex')\n",
        "ovr = OneVsRest(classifier=lr, \\\n",
        "                labelCol='labelIndex', \\\n",
        "                featuresCol='features')\n",
        "#from pyspark.ml import Pipeline\n",
        "#pipeline_ovr = Pipeline(stages=[vecAssembler, stdScaler, ovr])\n",
        "#pipelineModel_ovr = pipeline_ovr.fit(trainDF)\n",
        "\n",
        "ovrModel = ovr.fit(train)\n",
        "predictionsovr = ovrModel.transform(test)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\\\n",
        "labelCol=\"labelIndex\", predictionCol=\"prediction\",\\\n",
        "metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictionsovr)\n",
        "print(\"Test accuracy =  \" , accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_BEQVM3pVLR",
        "outputId": "0e5c2bd8-ea87-46a2-9597-088d74c584da"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy =   0.9787234042553191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KsTVcbY7p8cA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}